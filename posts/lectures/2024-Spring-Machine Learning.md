---
code: 4471037
title: "기계 학습 / Machine Learning"
year: 2024
semester: spring
division: "2분반"
description: "This course covers theoretical backgrounds and practical implementation of different machine learning techniques, including supervised learning, unsupervised learning, deep learning, active learning, anmd reinforcement learning. In addition, it explores the entire pipeline to build applications of machine learning with practices. Furthermore, it provides a broad introduction to ethical issues relevant to machine learning."
---
# Instruction
## Course Staff
* 강의자: 최우혁
    * 연구실: 공학 6호관 407호
    * 이메일: woohyeok.choi@kangwon.ac.kr

## Time & Location
* 월/목요일 12:00 - 13:45, 공학 6호관 608호

## Office Hours
* 화요일 13:00 - 15:00
* 주의 사항
    * 수업 및 과제 관련 내용은 면담 대신 e루리 질의 응답 게시판에 올려서 모든 학생이 공유할 수 있도록 할 것
    * 수업 및 과제 관련 내용을 제외한 면담이 필요시 미리 이메일로 연락하여 일정을 잡을 것

## Textbook
* Primary 
  * [Ge23] Aurélien Géron. 2023. Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems, 3rd Ed. O`Reilly
* Secondary
  * [Oh21] 오일석. 2021. 기계 학습. 한빛 아카데미
  * [Ow22] Louis Owen. 2022. Hyperparameter Tuning with Python: Boost your machine learning model’s performance via hyperparameter tuning. Packt.
  * [Br20] Jason Brownlee. 2020. Data Preparation for Machine Learning, 1.1 Ed. Machine Learning Mastery
  * [Br21] Jason Brownlee. 2021. Imbalanced Classification with Python, 1.3 Ed. Machine Learning Mastery
## Prerequisite
* (필수) 파이선 프로그래밍
* (선택) 자료 구조, 선형 대수학, 데이터 분석 프로그래밍

## Grading Policy
- 팀 과제 40%: Activity Recognition 데이터 수집 및 학습 모델 검증
  - 데이터 제출: 10%
  - ML 성능 평가 30%
- 개인 과제: 30%
  - Kaggle Challenge 6회 (각 5%)
- 중간 고사: 20%
  - Kaggle Challenge 1회
- 출석: 10%
  - 지각 3회 = 결석 1회
  - 결석 1회에 출석 점수 1% 차감
  - 총 수업 일의 1/3 (10회) 초과 결석 시 F
    - 즉, 11회 이상 결석 시 F
  - 별도의 사유(예. 예비군 훈련 등)가 있을 시 수업 시간 전에 교수에게 이메일 송부
    - 단, 급하게 벌어진 사유(예. 급병, 친족상 등)는 소명 자료를 제출

# Schedule
## W01: Overview
### March 04: Overview
* Materials
  * Lecture
* References: None
### March 07: Machine Learning Landscape
* Reference
  * [Ge23] Chap. 1
  * [Oh21] Chap. 1
* Materials
  * Lecture

## W02: Machine Learning Pipeline
### March 11: Theory
* Reference
  * [Ge23] Chap. 2
  * D. Sculley et al. 2015. Hidden technical debt in Machine learning systems. In Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2 (NIPS'15). MIT Press, Cambridge
* Materials
  * Lecture


### March 14: End-to-End Practice
* Reference
  * [Ge23] Chap. 3
* Materials
  * Lab
* Assignments
  * Ind. #1 (- March 20)

## W03: Linear Model
### March 18: 1st Order Linear Model
* Reference
  * [Ge23] Chap. 4
  * [Oh21] Chap. 2
* Materials
  * Lecture
  * Lab

### March 21: Polynomial Model, Regularized Linear Model, and Logistic Regression
* Reference
  * [Ge23] Chap. 4
  * [Oh21] Chap. 2
* Materials
  * Lecture
  * Lab

## W04: Support Vector Machine and Decision Tree
### March 25: Support Vector Machine
* Reference
  * [Ge23] Chap. 5
  * [Oh21] Chap. 11
* Materials
  * Lecture
  * Lab

### March 28: Decision Tree
* Reference
  * [Ge23] Chap. 6
* Materials
  * Lecture
  * Lab
* Assignments
  * Ind. #2 (- April 03)

## W05: Ensemble Model
### April 01: Random Forest
* Reference
  * [Ge23] Chap. 7
  * [Oh21] Chap. 12
* Materials
  * Lecture
  * Lab

### April 04: Gradient Boosted Tree
* Reference
  * [Ge23] Chap. 7
* Materials
  * Lecture
  * Lab

## W06: Feature Engineering #1
### April 08: Feature Extraction
* Reference
  * Andreas Bulling et al. 2014. A tutorial on human activity recognition using body-worn inertial sensors. ACM Comput. Surv. 46, 3,   Article 33.
  * Soujanya Poria et al. 2017. A review of affective computing: From unimodal analysis to multimodal fusion. Information Fusion, 37, 98–125.
* Materials
  * Lecture
  * Lab

### April 11: Feature Selection
* Reference
  * [Br20] Chap. 4
* Materials
  * Lecture
  * Lab
* Assignments
  * Ind. #3 (- April 17)

## W07: Feature Engineering #2
### April 15: Dimensionality Reduction
* Reference
  * [Ge23] Chap. 8
  * [Br20] Chap. 7
* Materials
  * Lecture
  * Lab

### April 18: Balancing Label Distribution
* Reference
  * [Br21] Chap. 4
* Materials
  * Lecture
  * Lab

## W08: Midterm
* Individual Kaggle Challenge

## W09: Cross-Validation and Hyperparamter Tuning
### April 29: Cross-Validation
* Reference
  * Berrar, D. 2019. Cross-Validation
* Materials
  * Lecture
  * Lab
* Assignments
  * Team #1 (- May 12)

### May 02: Hyperparamter Tuning
* Reference
  * [Ow22] Chap. 2, 3, 4, 7, 8, 9.
  * Tong Yu and Hong Zhu. 2000. Hyper-Parameter Optimization: A Review of Algorithms and Applications
* Materials
  * Lecture
  * Lab

## W10: Unsupervised Learning
### May 06: 어린이날 대체 휴일

### May 09: Clustering
* References
  * [Ge23] Chap. 9
  * [Oh21] Chap. 6
* Materials
  * Lecture
  * Lab
* Ind. #4 (- May 15)


## W11: Artificial Neural Network
### May 13: Anomaly Detection
* References
  * [Ge23] Chap. 9
  * [Oh21] Chap. 6
* Materials
  * Lecture
  * Lab

### May 16: Artificial Neural Network #1
* References
  * [Ge23] Chap. 10
  * [Oh21] Chap. 3
* Materials
  * Lecture
  * Lab


## W12: Deep Neural Network
### May 20: Artificial Neural Network #1
* References
  * [Ge23] Chap. 10
  * [Oh21] Chap. 3
* Materials
  * Lecture
  * Lab
* Assignments
  * Team #2 (- June 20)

### May 23: Deep Neural Network #1
* References
  * [Ge23] Chap. 11
  * [Oh21] Chap. 4, 5
* Materials
  * Lecture
  * Lab
* Assignments
  * Ind. #5 (- May 29)


## W13: Convolution Neural Network #1
### May 27: Deep Neural Network #2
* References
  * [Ge23] Chap. 11
  * [Oh21] Chap. 4, 5
* Materials
  * Lecture
  * Lab

### May 30: Convolution Neural Network #1
* References
  * [Ge23] Chap. 14
  * [Oh21] Chap. 4
* Materials
  * Lecture
  * Lab

## W14: Convolution Neural Network #2
### June 03: Convolution Neural Network #2
* References
  * [Ge23] Chap. 14
  * [Oh21] Chap. 4
* Materials
  * Lecture
  * Lab
* Assignments
  * Ind. #6 (- June 12)
### June 06: 현충일

## W15: Recurrent Neural Network
### June 10: Recurrent Neural Network #1
* References
  * [Ge23] Chap. 15
  * [Oh21] Chap. 8
* Materials
  * Lecture
  * Lab

### June 13: Recurrent Neural Network #2
* References
  * [Ge23] Chap. 15
  * [Oh21] Chap. 8
* Materials
  * Lecture
  * Lab

## W16: Final Term
* Team Project