{"componentChunkName":"component---src-components-lectures-template-tsx-content-file-path-posts-lectures-2026-spring-reinforcement-learning-md","path":"/lectures/59eecbb3-23ad-5cfc-af5d-948b1a931708/","result":{"data":{"lecture":{"frontmatter":{"code":"-","title":"Reinforcement Learning","year":"2026","semester":"spring","division":"1 Div.","description":"Reinforcement learning (RL) is one of the popular machine learning paradigms for solving sequential decision-making problems. In this paradigm, agents learn the optimal policies by repeatedly interacting with an environment to maximize (cumulative) rewards. This courses will cover the foundational concepts of RL, including state-action-reward pairs, the Markov decision process, and exploration versus exploitation. In addition, we will learn key RL algorithms, such as the Monte Carlo method, temporal difference learning, function approximation, and policy gradients. Furthermore, you will work on a small team project to implement an RL agent to solve problems with different difficulties, from simple to complex ones."},"tableOfContents":{"items":[{"url":"#instruction","title":"Instruction","items":[{"url":"#course-staff","title":"Course Staff"},{"url":"#time--location","title":"Time & Location"},{"url":"#office-hours","title":"Office Hours"},{"url":"#textbook","title":"Textbook"},{"url":"#prerequisite","title":"Prerequisite"},{"url":"#grading-policy","title":"Grading Policy","items":[{"url":"#reinforcement-learning-competitions-90","title":"Reinforcement Learning Competitions (90%)"},{"url":"#attendance-10","title":"Attendance (10%)"}]}]},{"url":"#schedule","title":"Schedule","items":[{"url":"#week-01","title":"Week 01","items":[{"url":"#march-05--overview--logistics","title":"March 05 — Overview & Logistics"},{"url":"#march-09--basic-math","title":"March 09 — Basic Math"}]},{"url":"#week-02","title":"Week 02","items":[{"url":"#march-12--introduction-to-reinforcement-learning","title":"March 12 — Introduction to Reinforcement Learning"},{"url":"#march-16--multi-armed-bandits","title":"March 16 — Multi-Armed Bandits"}]},{"url":"#week-03","title":"Week 03","items":[{"url":"#march-19--markov-process","title":"March 19 — Markov Process"},{"url":"#march-23--dynamic-programming","title":"March 23 — Dynamic Programming"}]},{"url":"#week-04","title":"Week 04","items":[{"url":"#march-26--tutorial-on-gymnasium","title":"March 26 — Tutorial on Gymnasium"},{"url":"#march-30--monte-carlo-methods-on-policy-methods","title":"March 30 — Monte-Carlo Methods: On-Policy Methods"}]},{"url":"#week-05","title":"Week 05","items":[{"url":"#april-02--monte-carlo-methods-off-policy-methods","title":"April 02 — Monte-Carlo Methods: Off-Policy Methods"},{"url":"#april-06--competition-round-0-tba","title":"April 06 — Competition Round 0: TBA"}]},{"url":"#week-06","title":"Week 06","items":[{"url":"#april-09--temporal-difference-learning","title":"April 09 — Temporal Difference Learning"},{"url":"#april-13--n-step-bootstrapping","title":"April 13 — n-Step Bootstrapping"}]},{"url":"#week-07","title":"Week 07","items":[{"url":"#april-16--planning--learning","title":"April 16 — Planning & Learning"},{"url":"#april-20--linear-function-approximation","title":"April 20 — Linear Function Approximation"}]},{"url":"#week-08","title":"Week 08","items":[{"url":"#april-23--competition-round-1-tba","title":"April 23 — Competition Round 1: TBA"},{"url":"#april-27--nonlinear-function-approximation-deep-neural-network","title":"April 27 — Nonlinear Function Approximation: Deep Neural Network"}]},{"url":"#week-09","title":"Week 09","items":[{"url":"#april-30--nonlinear-function-approximation-convolution-neural-network","title":"April 30 — Nonlinear Function Approximation: Convolution Neural Network"},{"url":"#may-04--practice-on-function-approximation","title":"May 04 — Practice on Function Approximation"}]},{"url":"#week-10","title":"Week 10","items":[{"url":"#may-07--deep-q-network","title":"May 07 — Deep-Q Network"},{"url":"#may-11--competition-round-2-tba","title":"May 11 — Competition Round 2: TBA"}]},{"url":"#week-11","title":"Week 11","items":[{"url":"#may-14--policy-gradient-methods","title":"May 14 — Policy Gradient Methods"},{"url":"#may-18--practice-on-policy-gradient-methods","title":"May 18 — Practice on Policy Gradient Methods"}]},{"url":"#week-12","title":"Week 12","items":[{"url":"#may-21--advanced-topics-variants-of-dqn--asynchronous-methods","title":"May 21 — Advanced Topics: Variants of DQN / Asynchronous Methods"},{"url":"#may-25--buddhas-birthday","title":"May 25 — Buddha's Birthday"}]},{"url":"#week-13","title":"Week 13","items":[{"url":"#may-28--competition-round-3-tba","title":"May 28 — Competition Round 3: TBA"},{"url":"#june-01--advanced-topics-deterministic-policy-gradient-methods","title":"June 01 — Advanced Topics: Deterministic Policy Gradient Methods"}]},{"url":"#week-14","title":"Week 14","items":[{"url":"#june-04--advanced-topics-entropy-regularized-methods","title":"June 04 — Advanced Topics: Entropy-Regularized Methods"},{"url":"#june-08--advanced-topics-trust-region-constraint-methods","title":"June 08 — Advanced Topics: Trust Region Constraint Methods"}]},{"url":"#week-15","title":"Week 15","items":[{"url":"#june-11--focus-on-rl-final-competition","title":"June 11 — Focus on RL Final Competition"},{"url":"#june-15--competition-round-4-tba","title":"June 15 — Competition Round 4: TBA"}]},{"url":"#week-16","title":"Week 16","items":[{"url":"#june-18--final-remark","title":"June 18 — Final Remark"}]}]}]}}},"pageContext":{"id":"59eecbb3-23ad-5cfc-af5d-948b1a931708","frontmatter":{"code":"-","year":"2026","semester":"spring","division":"1 Div.","title":"Reinforcement Learning","types":"major","description":"Reinforcement learning (RL) is one of the popular machine learning paradigms for solving sequential decision-making problems. In this paradigm, agents learn the optimal policies by repeatedly interacting with an environment to maximize (cumulative) rewards. This courses will cover the foundational concepts of RL, including state-action-reward pairs, the Markov decision process, and exploration versus exploitation. In addition, we will learn key RL algorithms, such as the Monte Carlo method, temporal difference learning, function approximation, and policy gradients. Furthermore, you will work on a small team project to implement an RL agent to solve problems with different difficulties, from simple to complex ones."}}},"staticQueryHashes":["3751811173","892254660"],"slicesMap":{}}